<h1 id='overview'>Overview</h1>
<p>Label propagation algorithm can be served as a way to detect communities in a directed/undirected graph. In a traditional label propagation algorithm, each node chooses the label occurring with the highest frequency among its neighbor list. This operation is very difficult to implement in parallel on the GPU. Instead, we use weighted label propagation, which assigns the label of the neighbor node that connects with the source node with the largest weighted edge. Reference paper: 
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012870&amp;tag=1">Fast Community Detection Algorithm with GPUs and Multicore Architectures</a></p>
<h1 id='edge-weight-assign'>Edge Weight Assign</h1>
<p>edge weight can be assigned using the following equation:</p>

<p>weight(e(s,d)) = tc_count(e(s,d))/ sum_{k \in neighbor(s)} tc_count(e(s,k))</p>

<p>tc_count(e) is the number of triangles with one edge as e. This can be acquired by running a triangle counting and keep the tc_count for each edge, then do reduce by key according to source node ID.</p>
<h1 id='per-vertex-and-per-edge-data'>Per-Vertex and Per-Edge Data</h1>
<p><code>// per-vertex</code></p>

<p><code>label[vid] = vid // result community label (starting with vid)</code></p>

<p><code>reduced_vid[vid] = GR_INVALID_NODE_VAL //initialized as invalid</code></p>

<p><code>node_weight[vid]</code> = max(weight[e]) // max edge weights in neighborhood. can be computed via one pass of advance</p>

<p><code>// per-edge</code></p>

<p><code>weight[eid] = compute_edge_weight() // pre-compute edge weights</code></p>
<h1 id='primitives'>Primitives</h1>
<p>Initialize edges e(u,v) where node_weight[u]==node_weight[v] as active edge,
run connected component on the graph, update some label values.</p>
<h1 id='update-weights'>Update Weights</h1>
<p>form a key value pair arrays where keys are labels, values are (degree, node weight) tuples.</p>

<p>W_l(L_i) = 1 - d_c/2M</p>

<p>W_l can be viewed as a regularizer for a specific label L_i (when more nodes in L_i, the impact gets lower)
d_c is the sum of degree for all nodes with label L_i. M is the edge number.</p>

<p>S_l(L_i) = \sum node_weight(u) where label[u] == L_i</p>

<p>These can be computed by segmented sort by labels as key and degree-weight tuple as value then reduce by key (label) or with current Gunrock operators, atomicAdd().</p>
<h1 id='functor-and-operator'>Functor and Operator</h1>
<p>The algorithm uses an advance with reduce_by_key and a parallel compute:</p>

<p>Advance: reduce_op is argmax of W_l(L_i)*S_l(L_i), key is vertex ID (cannot use labels directly as key since they are not adjacent).
{Cond,Apply}Edge both default one (keep all edges)</p>

<p>Compute Apply code (for all vertices):</p>

<p><code>if (label[vid] != label[reduced_vid[vid]])</code></p>

<p><code>label[vid] = label[reduced_vid[vid]]</code></p>
<h1 id='stop-condition'>Stop Condition</h1>
<p>reached max step or all labels are stable. This is the same as Pagerank.</p>
<h1 id='enactor'>Enactor</h1>
<p><code>f = Frontier.Init(All_Edges)</code></p>

<p><code>while (!all_label_stable &amp;&amp; iteration &lt; max_step)</code></p>

<p><code>{</code></p>

<p><code>UpdateWeights</code></p>

<p><code>Advance_with_Reduce(f, f_out)</code></p>

<p><code>Compute(f_out)</code></p>

<p><code>}</code></p>
